# CPS æ³¨æ„åŠ›æœºåˆ¶æ”¹è¿›è®¡åˆ’

## ğŸ“‹ é—®é¢˜æ¦‚è¿°

**æ ¸å¿ƒé—®é¢˜**: CPSæ¨¡å‹è®­ç»ƒ200æ¬¡ä»¥ä¸Šåï¼Œæ³¨æ„åŠ›å¾—åˆ†çš„å¤šå¤´å‡å€¼é€€åŒ–æˆç›¸åŒï¼Œæ— æ³•çœ‹å‡ºåœ¨ä¸åŒç©ºé—´åŸŸçš„å·®å¼‚ã€‚

**ç”¨æˆ·å·²å°è¯•çš„ä¿®æ”¹**:
1. ä¿®æ”¹å›¾å·ç§¯çš„alphaå‚æ•°
2. ä¿®æ”¹è‡ªç¯è®¾ç½®
3. å°è¯•å…±äº«QKVæƒé‡

**å½“å‰æ•ˆæœ**: è¿™äº›ä¿®æ”¹æœ‰ä¸€å®šå¸®åŠ©ï¼Œä½†æœªæ ¹æœ¬è§£å†³é—®é¢˜ã€‚

## ğŸ” æ ¹æœ¬åŸå› åˆ†æ

### 1. æ¸©åº¦å‚æ•°é—®é¢˜
- **ä½ç½®**: `CPS/model.py`ç¬¬120è¡Œ
- **é—®é¢˜**: å›ºå®šæ¸©åº¦å‚æ•°`temperature=2.3`ï¼Œ`exp(2.3)â‰ˆ9.97`è¿‡å¤§
- **å½±å“**: å¯¼è‡´softmaxåçš„æ³¨æ„åŠ›æƒé‡è¿‡äºå‡åŒ€

### 2. æŸ¥è¯¢å‘é‡è®¾è®¡é—®é¢˜
- **ä½ç½®**: `CPS/model.py`ç¬¬138è¡Œï¼ˆå½“`share_weights=False`æ—¶ï¼‰
- **é—®é¢˜**: æ‰€æœ‰å°ºåº¦çš„æŸ¥è¯¢å‘é‡éƒ½æ¥è‡ªç¬¬ä¸€ä¸ªå°ºåº¦ï¼ˆ`scale_features[:,0,:]`ï¼‰
- **å½±å“**: é™åˆ¶äº†æŸ¥è¯¢å¤šæ ·æ€§ï¼Œå¤šå¤´å®¹æ˜“æ”¶æ•›åˆ°ç›¸åŒæ¨¡å¼

### 3. æ³¨æ„åŠ›dropoutç­–ç•¥é—®é¢˜
- **ä½ç½®**: `CPS/model.py`ç¬¬151è¡Œ
- **é—®é¢˜**: åœ¨softmaxååº”ç”¨dropout
- **å½±å“**: å¯èƒ½å¯¼è‡´æ³¨æ„åŠ›ä¿¡æ¯ä¸¢å¤±ï¼Œè®­ç»ƒåæœŸæ¨¡å‹å­¦ä¹ å¿½ç•¥dropout

### 4. ç¼ºä¹å¤šæ ·æ€§çº¦æŸ
- **é—®é¢˜**: æ²¡æœ‰æ˜ç¡®çš„æœºåˆ¶é¼“åŠ±å¤šå¤´å­¦ä¹ ä¸åŒæ¨¡å¼
- **å½±å“**: å¤šå¤´æ³¨æ„åŠ›å®¹æ˜“å‘ç”Ÿæ¨¡å¼åå¡Œ

## ğŸš€ æ”¹è¿›æ–¹æ¡ˆ

### é˜¶æ®µä¸€ï¼šç«‹å³å®æ–½çš„å¿«é€Ÿä¿®å¤ï¼ˆ1-2å¤©ï¼‰

#### 1.1 æ¸©åº¦å‚æ•°ä¼˜åŒ–
```python
# å½“å‰ä»£ç ï¼ˆmodel.pyç¬¬120è¡Œï¼‰:
self.temperature = nn.Parameter(torch.ones(1) * 2.3)

# æ”¹è¿›æ–¹æ¡ˆï¼š
self.temperature = nn.Parameter(torch.ones(1) * 1.0)  # æ›´åˆç†çš„åˆå§‹å€¼
self.temperature_min = 0.1
self.temperature_max = 5.0

# åœ¨forwardä¸­ï¼ˆç¬¬148è¡Œï¼‰:
temperature = self.temperature.clamp(self.temperature_min, self.temperature_max)
scale = torch.exp(temperature) / (self.head_dim ** 0.5)
```

#### 1.2 æŸ¥è¯¢å‘é‡å¤šæ ·åŒ–
```python
# å½“å‰ä»£ç ï¼ˆmodel.pyç¬¬138è¡Œï¼‰:
q = q_proj(scale_features[:,0,:])  # æ‰€æœ‰å°ºåº¦ä½¿ç”¨ç›¸åŒçš„æŸ¥è¯¢æº

# æ”¹è¿›æ–¹æ¡ˆ1ï¼šæ¯ä¸ªå°ºåº¦ä½¿ç”¨è‡ªå·±çš„ç‰¹å¾
q = q_proj(scale_features[:,i,:])  # ç¬¬iä¸ªå°ºåº¦ä½¿ç”¨ç¬¬iä¸ªå°ºåº¦çš„ç‰¹å¾

# æˆ–æ”¹è¿›æ–¹æ¡ˆ2ï¼šæ··åˆæŸ¥è¯¢æº
if self.share_weights:
    # ä½¿ç”¨æ‰€æœ‰å°ºåº¦çš„åŠ æƒå¹³å‡
    query_source = scale_features.mean(dim=1)
else:
    # æ¯ä¸ªå°ºåº¦ä½¿ç”¨è‡ªå·±çš„ç‰¹å¾
    query_source = scale_features[:,i,:]
```

#### 1.3 Dropoutç­–ç•¥è°ƒæ•´
```python
# å½“å‰ä»£ç ï¼ˆmodel.pyç¬¬150-151è¡Œï¼‰:
attn_weights = F.softmax(attn_scores, dim=1)
attn_weights = self.dropout(attn_weights)

# æ”¹è¿›æ–¹æ¡ˆï¼šåœ¨softmaxå‰åº”ç”¨dropout
attn_scores = self.dropout(attn_scores)  # å…ˆdropout
attn_weights = F.softmax(attn_scores, dim=1)  # åsoftmax
```

### é˜¶æ®µäºŒï¼šä¸­çº§æ”¹è¿›ï¼ˆ3-5å¤©ï¼‰

#### 2.1 æ³¨æ„åŠ›å¤šæ ·æ€§æ­£åˆ™åŒ–
```python
class AttentionDiversityLoss(nn.Module):
    def __init__(self, lambda_div=0.1):
        super().__init__()
        self.lambda_div = lambda_div
    
    def forward(self, attn_weights):
        # attn_weightså½¢çŠ¶: (N, S, H)
        # è®¡ç®—å¤´é—´ç›¸ä¼¼åº¦
        attn_flat = attn_weights.mean(dim=1)  # (N, H)
        similarity = F.cosine_similarity(
            attn_flat.unsqueeze(1),  # (N, 1, H)
            attn_flat.unsqueeze(0),  # (1, N, H)
            dim=2
        )
        # æ’é™¤å¯¹è§’çº¿
        mask = 1 - torch.eye(similarity.size(0), device=similarity.device)
        diversity_loss = (similarity * mask).sum() / mask.sum()
        
        return self.lambda_div * diversity_loss

# åœ¨è®­ç»ƒå¾ªç¯ä¸­æ·»åŠ 
diversity_loss = diversity_criterion(attn_weights)
total_loss = losses['total'] + diversity_loss
```

#### 2.2 å¤šå¤´ç‹¬ç«‹æ¸©åº¦å‚æ•°
```python
# æ¯ä¸ªæ³¨æ„åŠ›å¤´æœ‰è‡ªå·±çš„æ¸©åº¦å‚æ•°
self.temperatures = nn.Parameter(torch.ones(num_heads) * 1.0)

# åœ¨forwardä¸­
scale = torch.exp(self.temperatures).view(1, 1, -1) / (self.head_dim ** 0.5)
attn_scores = torch.einsum('nhd,nshd->nsh', query, keys) / (self.head_dim ** 0.5)
attn_scores = attn_scores * scale  # æ¯ä¸ªå¤´ä¸åŒçš„ç¼©æ”¾
```

#### 2.3 å°ºåº¦ç‰¹å¼‚æ€§å¢å¼º
```python
def compute_scale_specificity(attn_weights, spatial_coords, radius=50):
    """é¼“åŠ±ä¸åŒå°ºåº¦å…³æ³¨ä¸åŒçš„ç©ºé—´åŒºåŸŸ"""
    specificity_loss = 0
    n_scales = attn_weights.shape[1]
    
    for i in range(n_scales):
        for j in range(i+1, n_scales):
            # è®¡ç®—ä¸¤ä¸ªå°ºåº¦æ³¨æ„åŠ›æƒé‡çš„ç©ºé—´ç›¸å…³æ€§
            attn_i = attn_weights[:, i, :].mean(dim=1)  # (N,)
            attn_j = attn_weights[:, j, :].mean(dim=1)  # (N,)
            
            # è®¡ç®—å±€éƒ¨ç©ºé—´ç›¸å…³æ€§
            local_corr = compute_local_correlation(
                attn_i, attn_j, spatial_coords, radius
            )
            # æƒ©ç½šé«˜ç›¸å…³æ€§ï¼ˆé¼“åŠ±å·®å¼‚ï¼‰
            specificity_loss += torch.abs(local_corr)
    
    return specificity_loss / (n_scales * (n_scales - 1) / 2)
```

### é˜¶æ®µä¸‰ï¼šé«˜çº§æ¶æ„æ”¹è¿›ï¼ˆ1-2å‘¨ï¼‰

#### 3.1 å¯å­¦ä¹ æŸ¥è¯¢å‘é‡
```python
class LearnableQueryAttention(nn.Module):
    def __init__(self, num_heads, head_dim, num_scales):
        super().__init__()
        # å¯å­¦ä¹ çš„æŸ¥è¯¢å‘é‡ï¼Œæ¯ä¸ªå¤´ã€æ¯ä¸ªå°ºåº¦ç‹¬ç«‹
        self.learnable_queries = nn.Parameter(
            torch.randn(num_heads, num_scales, head_dim)
        )
        # å¯å­¦ä¹ çš„æŸ¥è¯¢æƒé‡ï¼Œå†³å®šæ¯ä¸ªå°ºåº¦çš„é‡è¦æ€§
        self.query_weights = nn.Parameter(torch.ones(num_heads, num_scales))
    
    def forward(self, scale_features):
        N = scale_features.shape[0]
        # ç”ŸæˆæŸ¥è¯¢å‘é‡
        queries = torch.einsum('hsd,hs->hd', 
                              self.learnable_queries,
                              F.softmax(self.query_weights, dim=1))
        queries = queries.unsqueeze(0).expand(N, -1, -1)  # (N, H, D_h)
        return queries
```

#### 3.2 æ³¨æ„åŠ›å¤´ä¸“ä¸šåŒ–
```python
class SpecializedAttentionHeads(nn.Module):
    def __init__(self, num_heads, specialization_types=['local', 'global', 'boundary']):
        super().__init__()
        self.specialization_types = specialization_types
        self.num_specializations = len(specialization_types)
        
        # æ¯ä¸ªä¸“ä¸šåŒ–ç±»å‹æœ‰å¯¹åº”çš„å¤´
        self.heads_per_type = num_heads // self.num_specializations
        
        # ä¸“ä¸šåŒ–ç‰¹å®šçš„åˆå§‹åŒ–
        self.specialized_inits = {
            'local': {'temperature': 0.5, 'query_bias': 'near'},
            'global': {'temperature': 2.0, 'query_bias': 'far'},
            'boundary': {'temperature': 1.0, 'query_bias': 'gradient'}
        }
```

#### 3.3 æ¸è¿›å¼æ³¨æ„åŠ›è®­ç»ƒ
```python
class ProgressiveAttentionTraining:
    def __init__(self, total_epochs=200):
        self.total_epochs = total_epochs
        self.current_epoch = 0
        
        # è®­ç»ƒé˜¶æ®µå®šä¹‰
        self.phases = [
            {'epochs': 50, 'diversity_weight': 0.2, 'temperature': 'high'},
            {'epochs': 100, 'diversity_weight': 0.1, 'temperature': 'medium'},
            {'epochs': 50, 'diversity_weight': 0.05, 'temperature': 'low'}
        ]
    
    def get_current_config(self):
        # æ ¹æ®å½“å‰epochè¿”å›é…ç½®
        epoch_sum = 0
        for phase in self.phases:
            epoch_sum += phase['epochs']
            if self.current_epoch <= epoch_sum:
                return phase
        return self.phases[-1]
```

## ğŸ§ª å®éªŒéªŒè¯è®¡åˆ’

### å®éªŒç»„è®¾è®¡
| å®éªŒç»„ | æ”¹è¿›æªæ–½ | é¢„æœŸæ•ˆæœ | ä¼˜å…ˆçº§ |
|--------|----------|----------|--------|
| A1 | æ¸©åº¦å‚æ•°ä¼˜åŒ– + æŸ¥è¯¢å¤šæ ·åŒ– | å¿«é€ŸéªŒè¯ï¼Œç«‹å³æ”¹å–„ | é«˜ |
| A2 | A1 + æ³¨æ„åŠ›å¤šæ ·æ€§æ­£åˆ™åŒ– | è¿›ä¸€æ­¥æ”¹å–„å¤šæ ·æ€§ | é«˜ |
| B1 | å¤šå¤´ç‹¬ç«‹æ¸©åº¦ + å°ºåº¦ç‰¹å¼‚æ€§ | å¢å¼ºå°ºåº¦å·®å¼‚ | ä¸­ |
| B2 | å¯å­¦ä¹ æŸ¥è¯¢å‘é‡ | æ›´çµæ´»çš„æ³¨æ„åŠ›æ¨¡å¼ | ä¸­ |
| C1 | æ¸è¿›å¼è®­ç»ƒç­–ç•¥ | ç¨³å®šè®­ç»ƒè¿‡ç¨‹ | ä½ |
| C2 | å®Œæ•´æ¶æ„æ”¹è¿› | ç»¼åˆæœ€ä¼˜æ•ˆæœ | ä½ |

### è¯„ä¼°æŒ‡æ ‡
1. **æ³¨æ„åŠ›å¤šæ ·æ€§å¾—åˆ†**: è®¡ç®—å¤šå¤´æ³¨æ„åŠ›çš„å·®å¼‚åº¦
2. **å°ºåº¦ç‰¹å¼‚æ€§**: ä¸åŒå°ºåº¦æ³¨æ„åŠ›æƒé‡çš„ç©ºé—´å·®å¼‚
3. **è®­ç»ƒç¨³å®šæ€§**: æŸå¤±æ›²çº¿å’Œæ³¨æ„åŠ›ç†µçš„å˜åŒ–
4. **ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½**: åŸºå› è¡¨è¾¾é‡å»ºè¯¯å·®
5. **å¯è§†åŒ–è´¨é‡**: æ³¨æ„åŠ›æ¨¡å¼çš„ç©ºé—´å¯è§£é‡Šæ€§

### æ•°æ®é›†
1. **DLPFC**: æ ‡å‡†Visiumæ•°æ®ï¼Œ7ä¸ªç©ºé—´åŸŸ
2. **HBC**: VisiumHDé«˜åˆ†è¾¨ç‡æ•°æ®
3. **åˆæˆæ•°æ®**: ç”¨äºæ§åˆ¶å®éªŒéªŒè¯

## ğŸ“Š å®æ–½è·¯çº¿å›¾

### ç¬¬1å‘¨ï¼šå¿«é€Ÿä¿®å¤å’ŒéªŒè¯
- [ ] å®ç°æ¸©åº¦å‚æ•°ä¼˜åŒ–
- [ ] å®ç°æŸ¥è¯¢å‘é‡å¤šæ ·åŒ–
- [ ] è°ƒæ•´dropoutç­–ç•¥
- [ ] è¿è¡Œå®éªŒA1ï¼Œè¯„ä¼°æ•ˆæœ
- [ ] æ ¹æ®ç»“æœè°ƒæ•´å‚æ•°

### ç¬¬2å‘¨ï¼šæ­£åˆ™åŒ–å’Œä¸­çº§æ”¹è¿›
- [ ] å®ç°æ³¨æ„åŠ›å¤šæ ·æ€§æ­£åˆ™åŒ–
- [ ] å®ç°å¤šå¤´ç‹¬ç«‹æ¸©åº¦
- [ ] è¿è¡Œå®éªŒA2å’ŒB1
- [ ] åˆ†æå°ºåº¦ç‰¹å¼‚æ€§æ”¹å–„
- [ ] ä¼˜åŒ–æ­£åˆ™åŒ–æƒé‡

### ç¬¬3å‘¨ï¼šé«˜çº§æ¶æ„æ”¹è¿›
- [ ] å®ç°å¯å­¦ä¹ æŸ¥è¯¢å‘é‡
- [ ] å®ç°æ³¨æ„åŠ›å¤´ä¸“ä¸šåŒ–
- [ ] è¿è¡Œå®éªŒB2å’ŒC1
- [ ] è¿›è¡Œæ¶ˆèå®éªŒ
- [ ] ç¡®å®šæœ€ä½³é…ç½®

### ç¬¬4å‘¨ï¼šç»¼åˆæµ‹è¯•å’Œä¼˜åŒ–
- [ ] å®ç°å®Œæ•´æ¶æ„æ”¹è¿›
- [ ] è¿è¡Œå®éªŒC2
- [ ] è¿›è¡Œè·¨æ•°æ®é›†éªŒè¯
- [ ] æ€§èƒ½è°ƒä¼˜å’Œå‚æ•°æœç´¢
- [ ] ç¼–å†™æœ€ç»ˆæŠ¥å‘Š

## ğŸ”§ ä»£ç ä¿®æ”¹æŒ‡å—

### æ ¸å¿ƒæ–‡ä»¶ä¿®æ”¹
1. **`CPS/model.py`**:
   - `TeacherNicheAttention`ç±»çš„`__init__`å’Œ`forward`æ–¹æ³•
   - æ¸©åº¦å‚æ•°åˆå§‹åŒ–é€»è¾‘
   - æŸ¥è¯¢å‘é‡ç”Ÿæˆé€»è¾‘

2. **`CPS/cps.py`**:
   - `CPSTrainer`ç±»çš„`fit`æ–¹æ³•
   - æ·»åŠ å¤šæ ·æ€§æ­£åˆ™åŒ–æŸå¤±
   - ä¿®æ”¹è®­ç»ƒå¾ªç¯ç›‘æ§

3. **`CPS/config.py`**:
   - æ·»åŠ æ–°çš„é…ç½®å‚æ•°
   - æ¸©åº¦å‚æ•°èŒƒå›´è®¾ç½®
   - æ­£åˆ™åŒ–æƒé‡å‚æ•°

### æ–°æ–‡ä»¶åˆ›å»º
1. **`CPS/attention_utils.py`**:
   - æ³¨æ„åŠ›è¯„ä¼°å·¥å…·
   - å¤šæ ·æ€§è®¡ç®—å‡½æ•°
   - å¯è§†åŒ–å·¥å…·

2. **`CPS/attention_losses.py`**:
   - å¤šæ ·æ€§æŸå¤±å‡½æ•°
   - ç‰¹å¼‚æ€§æŸå¤±å‡½æ•°
   - ç»„åˆæŸå¤±å‡½æ•°

## ğŸ“ˆ é¢„æœŸæ•ˆæœ

### çŸ­æœŸç›®æ ‡ï¼ˆ1-2å‘¨ï¼‰
1. è§£å†³æ³¨æ„åŠ›é€€åŒ–é—®é¢˜
2. å®ç°æ˜æ˜¾çš„å¤šå¤´å·®å¼‚åŒ–
3. æé«˜æ³¨æ„åŠ›æ¨¡å¼çš„å¯è§£é‡Šæ€§
4. ä¿æŒæˆ–æé«˜ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½

### é•¿æœŸç›®æ ‡ï¼ˆ1ä¸ªæœˆï¼‰
1. å»ºç«‹ç¨³å®šçš„æ³¨æ„åŠ›è®­ç»ƒæ¡†æ¶
2. æä¾›å¯é…ç½®çš„æ³¨æ„åŠ›æœºåˆ¶
3. åœ¨å¤šä¸ªæ•°æ®é›†ä¸ŠéªŒè¯æ•ˆæœ
4. å‘è¡¨æ–¹æ³•æ”¹è¿›è®ºæ–‡

## âš ï¸ é£é™©ä¸ç¼“è§£

### é£é™©1ï¼šæ”¹è¿›å¯èƒ½å½±å“æ¨¡å‹æ€§èƒ½
- **ç¼“è§£**: é€æ­¥å®æ–½ï¼Œæ¯ä¸ªé˜¶æ®µéƒ½éªŒè¯ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½
- **ç›‘æ§**: åŒæ—¶è·Ÿè¸ªæ³¨æ„åŠ›è´¨é‡å’Œé‡å»ºè¯¯å·®

### é£é™©2ï¼šå¢åŠ æ¨¡å‹å¤æ‚åº¦
- **ç¼“è§£**: æä¾›é…ç½®é€‰é¡¹ï¼Œå…è®¸ç”¨æˆ·é€‰æ‹©å¤æ‚åº¦
- **ä¼˜åŒ–**: ç¡®ä¿æ–°å¢å‚æ•°æœ‰æ˜ç¡®çš„ç†è®ºä¾æ®

### é£é™©3ï¼šè®­ç»ƒä¸ç¨³å®š
- **ç¼“è§£**: å®ç°æ¸è¿›å¼è®­ç»ƒç­–ç•¥
- **ç›‘æ§**: æ·»åŠ è®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–å·¥å…·

## ğŸ¤ åä½œå»ºè®®

1. **ç‰ˆæœ¬æ§åˆ¶**: ä¸ºæ¯ä¸ªå®éªŒç»„åˆ›å»ºç‹¬ç«‹åˆ†æ”¯
2. **å®éªŒè®°å½•**: ä½¿ç”¨MLflowæˆ–W&Bè®°å½•å®éªŒ
3. **ä»£ç å®¡æŸ¥**: æ¯ä¸ªæ”¹è¿›æäº¤å‰è¿›è¡Œä»£ç å®¡æŸ¥
4. **å®šæœŸåŒæ­¥**: æ¯å‘¨åŒæ­¥è¿›å±•å’Œé—®é¢˜

---

**æœ€åæ›´æ–°**: 2025-12-27  
**ç‰ˆæœ¬**: 1.0  
**çŠ¶æ€**: å®æ–½è®¡åˆ’  
**è´Ÿè´£äºº**: æ¨¡å‹æ¶æ„å›¢é˜Ÿ